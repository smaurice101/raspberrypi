apiVersion: batch/v1
kind: Job
metadata:
  name: tml-parallel-csv
spec:
  ttlSecondsAfterFinished: 300  # Auto-delete after 5 minutes
  parallelism: 10  # 10 pods process in parallel
  completions: 100  # Process 100 CSVs total
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: tml-pipeline
        image: maadsdocker/testcon1:latest
        command: ["/bin/sh", "-c"]
        args:
        - |
          # Each pod gets unique index 0-99
          MY_INDEX=${POD_INDEX:-0}
          
          # Get Nth CSV file (0-based indexing)
          CSV_FILE=$(ls /tml/spreadsheets/*.csv | sort | sed -n "$((MY_INDEX + 1))p")
          
          if [ -f "$CSV_FILE" ]; then
            echo "Pod $MY_INDEX processing: $CSV_FILE"
            # Your tml-pipeline command
            # tml-pipeline --input "$CSV_FILE" --output "/tml/results/$(basename $CSV_FILE .csv)_result.csv"
            sleep 30  # Replace with processing
          fi
        env:
        - name: POD_INDEX
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['batch.kubernetes.io/job-index']  # Unique per pod
        volumeMounts:
        - mountPath: /tml/spreadsheets
          name: spreadsheets
        - mountPath: /tml/results
          name: results
      volumes:
      - name: spreadsheets
        hostPath:
          path: /tmp/tmlpipeline/spreadsheets
      - name: results
        hostPath:
          path: /tmp/tmlpipeline/results
          type: DirectoryOrCreate
